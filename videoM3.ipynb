{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taba4ek555/video_pocessing/blob/main/videoM3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaaPNH5g4x7u"
      },
      "source": [
        "# Интеллектуальные методы обработки видео\n",
        "\n",
        "## Модуль 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pNgjrMqQ4x72"
      },
      "outputs": [],
      "source": [
        "# Константы\n",
        "dataFolder = \"/content/data\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5c9eMmr4x76"
      },
      "source": [
        "### Чтение данных\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gr3EBCS4x77",
        "outputId": "8a8df94b-65a4-4096-994f-a75a2a0548df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video /content/data/result/temp_cut_video.avi.\n",
            "MoviePy - Writing audio in temp_cut_videoTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video /content/data/result/temp_cut_video.avi\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/data/result/temp_cut_video.avi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "# Загрузка видео в память и вырезание фрагмента\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "src_file_name = f\"{dataFolder}/result/final\"\n",
        "result_file_name = f\"{dataFolder}/result/temp_cut_video.avi\"\n",
        "\n",
        "# Загрузить видеофайл\n",
        "video = VideoFileClip(src_file_name)\n",
        "# Вырезать часть видео с 10 по 20 секунду\n",
        "cut_video = video.subclip(10, 25)\n",
        "# Сохранить вырезанный фрагмент в новый файл\n",
        "cut_video.write_videofile(result_file_name, codec=\"libx264\", preset=\"ultrafast\", bitrate=\"5000k\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLhu-kAJ4x8B",
        "outputId": "16745196-d207-4dd8-d401-efda4f1aaa5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytube in /usr/local/lib/python3.10/dist-packages (15.0.0)\n",
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.10/dist-packages (2024.12.13)\n",
            "[rutube] Extracting URL: https://rutube.ru/video/829d987a58681251afd104e2ea4562bb/\n",
            "[rutube] 829d987a58681251afd104e2ea4562bb: Downloading video JSON\n",
            "[rutube] 829d987a58681251afd104e2ea4562bb: Downloading options JSON\n",
            "[rutube] 829d987a58681251afd104e2ea4562bb: Downloading m3u8 information\n",
            "[rutube] 829d987a58681251afd104e2ea4562bb: Downloading m3u8 information\n",
            "[info] 829d987a58681251afd104e2ea4562bb: Downloading 1 format(s): m3u8-723-1\n",
            "[download] /content/data/result/final has already been downloaded\n",
            "[download] 100% of    4.95MiB\n",
            "Видео успешно скачано и сохранено в /content/data/result/\n"
          ]
        }
      ],
      "source": [
        "# Загрузка видео из Youtube\n",
        "!pip install pytube\n",
        "!pip install yt-dlp\n",
        "# Загрузка видео из Youtube\n",
        "from pytube import YouTube\n",
        "import yt_dlp\n",
        "\n",
        "# URL видео, которое вы хотите скачать\n",
        "video_url = \"https://rutube.ru/video/829d987a58681251afd104e2ea4562bb/\"\n",
        "\n",
        "ydl_opts = {\n",
        "    'outtmpl': f\"{dataFolder}/result/final\",\n",
        "}\n",
        "\n",
        "try:\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([video_url])\n",
        "    print(\"Видео успешно скачано и сохранено в\", f\"{dataFolder}/result/\")\n",
        "except Exception as e:\n",
        "    print(\"Ошибка:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QYW5Gvo74x8E"
      },
      "outputs": [],
      "source": [
        "# Используем opencv-python для чтения временного файла и сохранения его в формате FFV1:\n",
        "import cv2\n",
        "import os\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "src_file_name = result_file_name\n",
        "result_file_name = f\"{dataFolder}/result/final_cut_video.avi\"\n",
        "\n",
        "# Инициализировать объект VideoCapture для чтения временного файла\n",
        "cap = cv2.VideoCapture(src_file_name)\n",
        "\n",
        "# Получить параметры видео для создания VideoWriter\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# Инициализировать VideoWriter с кодеком FFV1\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"FFV1\")\n",
        "out = cv2.VideoWriter(result_file_name, fourcc, fps, (frame_width, frame_height), True)\n",
        "\n",
        "# Читать каждый кадр из временного файла и записывать его в новый файл с кодеком FFV1\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    out.write(frame)\n",
        "\n",
        "# Освободить ресурсы\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "# Удаление временного файла, если необходимо\n",
        "os.remove(src_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvsJUWeB4x8H",
        "outputId": "e332b6b0-9186-461d-cea5-a881a1055548"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Файл: /content/data/result/final_cut_video.avi\n",
            "Разрешение: 320x240\n",
            "Кодек: ffv1\n",
            "Количество кадров: 90\n",
            "FPS (Кадров в секунду): 6.0\n",
            "Продолжительность (секунды): 15.00\n"
          ]
        }
      ],
      "source": [
        "# Чтение свойств файлов\n",
        "import cv2\n",
        "\n",
        "result_file_name = f\"{dataFolder}/result/final_cut_video.avi\"\n",
        "\n",
        "\n",
        "def print_video_info(file_path):\n",
        "    # Открыть видеофайл\n",
        "    cap = cv2.VideoCapture(file_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(\"Ошибка при открытии файла\")\n",
        "        return\n",
        "\n",
        "    # Чтение параметров видео\n",
        "    width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "    height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    codec = int(cap.get(cv2.CAP_PROP_FOURCC))\n",
        "    codec_str = \"\".join([chr((codec >> 8 * i) & 0xFF) for i in range(4)])\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    duration = frame_count / fps if fps > 0 else 0\n",
        "\n",
        "    # Вывод информации\n",
        "    print(\"\\n\")\n",
        "    print(f\"Файл: {file_path}\")\n",
        "    print(f\"Разрешение: {int(width)}x{int(height)}\")\n",
        "    print(f\"Кодек: {codec_str}\")\n",
        "    print(f\"Количество кадров: {frame_count}\")\n",
        "    print(f\"FPS (Кадров в секунду): {fps}\")\n",
        "    print(f\"Продолжительность (секунды): {duration:.2f}\")\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "\n",
        "# Пример использования\n",
        "print_video_info(result_file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu4nJChc4x8K"
      },
      "source": [
        "### Используем метод оптического потока для стабилизации видео\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "lMlnXf8q4x8L"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "src_file_name = f\"{dataFolder}/result/final\"\n",
        "result_file_name = f\"{dataFolder}/result/optical_flow.avi\"\n",
        "\n",
        "\n",
        "def is_black_frame(frame, threshold=10):\n",
        "    \"\"\"Проверяет, является ли кадр черным.\"\"\"\n",
        "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    return np.mean(gray_frame) < threshold\n",
        "\n",
        "\n",
        "def stabilize_video(input_path, output_path):\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "\n",
        "    # Чтение первого кадра\n",
        "    ret, prev = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Не удалось прочитать видео\")\n",
        "        cap.release()\n",
        "        return\n",
        "\n",
        "    # Преобразование в градации серого\n",
        "    prev_gray = cv2.cvtColor(prev, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Параметры для детектора углов ShiTomasi\n",
        "    feature_params = dict(maxCorners=100, qualityLevel=0.03, minDistance=7, blockSize=7)\n",
        "\n",
        "    # Параметры для оптического потока Лукаса-Канаде\n",
        "    lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
        "\n",
        "    # Выбор точек для отслеживания\n",
        "    p0 = cv2.goodFeaturesToTrack(prev_gray, mask=None, **feature_params)\n",
        "\n",
        "    # Создание случайных цветов\n",
        "    color = np.random.randint(0, 255, (100, 3))\n",
        "\n",
        "    # Параметры для записи видео\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
        "    out = cv2.VideoWriter(output_path, fourcc, 20.0, (prev.shape[1], prev.shape[0]))\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if is_black_frame(frame):\n",
        "            out.write(frame)  # Сохраняем оригинальный черный кадр\n",
        "            # Переинициализируем точки после черного экрана\n",
        "            p0 = cv2.goodFeaturesToTrack(prev_gray, mask=None, **feature_params)\n",
        "            prev_gray = frame_gray\n",
        "            continue\n",
        "\n",
        "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Вычисление оптического потока\n",
        "        p1, st, err = cv2.calcOpticalFlowPyrLK(prev_gray, frame_gray, p0, None, **lk_params)\n",
        "\n",
        "        if p1 is not None:\n",
        "            # Выбор хороших точек\n",
        "            good_new = p1[st == 1]\n",
        "            good_old = p0[st == 1]\n",
        "        else:\n",
        "            # Использование последних известных хороших точек\n",
        "            good_new = good_old\n",
        "\n",
        "        # Рисование треков\n",
        "        # Рисование треков\n",
        "        for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
        "            a, b = new.ravel()\n",
        "            c, d = old.ravel()\n",
        "            frame = cv2.line(frame, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n",
        "            frame = cv2.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n",
        "\n",
        "        img = cv2.add(frame, np.zeros(np.shape(frame), dtype=np.uint8))\n",
        "        out.write(img)\n",
        "\n",
        "        # Обновление предыдущего кадра и предыдущих точек\n",
        "        prev_gray = frame_gray.copy()\n",
        "        p0 = good_new.reshape(-1, 1, 2)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "# Используйте функцию как stabilize_video('путь_к_исходному_видео', 'путь_к_стабилизированному_видео')\n",
        "stabilize_video(src_file_name, result_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "aETO7WoW4x8O"
      },
      "outputs": [],
      "source": [
        "# Итог\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "src_file_name = f\"{dataFolder}/result/final\"\n",
        "result_file_name = f\"{dataFolder}/result/optical_flow_stabilized.avi\"\n",
        "\n",
        "\n",
        "def is_black_frame(frame, threshold=10):\n",
        "    \"\"\"Проверяет, является ли кадр черным.\"\"\"\n",
        "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    return np.mean(gray_frame) < threshold\n",
        "\n",
        "\n",
        "def stabilize_video(input_path, output_path):\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "    ret, prev = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Не удалось прочитать видео\")\n",
        "        cap.release()\n",
        "        return\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    prev_gray = cv2.cvtColor(prev, cv2.COLOR_BGR2GRAY)\n",
        "    feature_params = dict(maxCorners=100, qualityLevel=0.03, minDistance=7, blockSize=7)\n",
        "    lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
        "    p0 = cv2.goodFeaturesToTrack(prev_gray, mask=None, **feature_params)\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (prev.shape[1], prev.shape[0]))\n",
        "\n",
        "    # Инициализация накопительной матрицы преобразований\n",
        "    cumulative_trans = np.float32([[1, 0, 0], [0, 1, 0]])\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        if is_black_frame(frame):\n",
        "            out.write(frame)\n",
        "            p0 = cv2.goodFeaturesToTrack(frame_gray, mask=None, **feature_params)\n",
        "            prev_gray = frame_gray\n",
        "            continue\n",
        "\n",
        "        p1, st, err = cv2.calcOpticalFlowPyrLK(prev_gray, frame_gray, p0, None, **lk_params)\n",
        "\n",
        "        if p1 is not None and st.any():\n",
        "            good_new = p1[st == 1]\n",
        "            good_old = p0[st == 1]\n",
        "\n",
        "            # Вычисление среднего смещения\n",
        "            displacements = good_new - good_old\n",
        "            dx_avg = np.mean(displacements[:, 0])\n",
        "            dy_avg = np.mean(displacements[:, 1])\n",
        "\n",
        "            # Обновление накопительной матрицы преобразований\n",
        "            cumulative_trans[0, 2] += -dx_avg\n",
        "            cumulative_trans[1, 2] += -dy_avg\n",
        "\n",
        "            # Применение скорректированного смещения\n",
        "            frame_stabilized = cv2.warpAffine(frame, cumulative_trans, (frame.shape[1], frame.shape[0]))\n",
        "\n",
        "            out.write(frame_stabilized)\n",
        "        else:\n",
        "            out.write(frame)\n",
        "\n",
        "        prev_gray = frame_gray.copy()\n",
        "        p0 = good_new.reshape(-1, 1, 2) if p1 is not None else p0\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "stabilize_video(src_file_name, result_file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myFkPcYS4x8S"
      },
      "source": [
        "### Используем готовый алгоритм stabilize библиотеки vidstab для стабилизации видео\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFAHkQl14x8T",
        "outputId": "0c3f80b6-0ba9-4d0e-f318-57a1d790f249"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting VidStab\n",
            "  Downloading vidstab-1.7.4-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from VidStab) (1.26.4)\n",
            "Requirement already satisfied: imutils>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from VidStab) (0.5.4)\n",
            "Collecting progress (from VidStab)\n",
            "  Downloading progress-1.6.tar.gz (7.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from VidStab) (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->VidStab) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->VidStab) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->VidStab) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->VidStab) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->VidStab) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->VidStab) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->VidStab) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->VidStab) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->VidStab) (1.17.0)\n",
            "Downloading vidstab-1.7.4-py2.py3-none-any.whl (26 kB)\n",
            "Building wheels for collected packages: progress\n",
            "  Building wheel for progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progress: filename=progress-1.6-py3-none-any.whl size=9613 sha256=1f92e33f0b3dda084c439650b87ec01c3d265cd3b9e0e695c3952025193f6b00\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/68/5f/c339b20a41659d856c93ccdce6a33095493eb82c3964aac5a1\n",
            "Successfully built progress\n",
            "Installing collected packages: progress, VidStab\n",
            "Successfully installed VidStab-1.7.4 progress-1.6\n",
            "Видео стабилизировано и сохранено в файл /content/data/result/stabilized_file.avi\n"
          ]
        }
      ],
      "source": [
        "!pip install VidStab\n",
        "from vidstab import VidStab\n",
        "\n",
        "\n",
        "\n",
        "src_file_name = f\"{dataFolder}/result/final\"\n",
        "result_file_name = f\"{dataFolder}/result/stabilized_file.avi\"\n",
        "\n",
        "\n",
        "\n",
        "# Инициализировать стабилизатор видео\n",
        "\n",
        "\n",
        "stabilizer = VidStab()\n",
        "\n",
        "\n",
        "\n",
        "# Стабилизировать исходное видео\n",
        "\n",
        "\n",
        "stabilizer.stabilize(input_path=src_file_name, output_path=result_file_name, output_fourcc=\"FFV1\")\n",
        "\n",
        "\n",
        "\n",
        "# Вывести сообщение об успешной стабилизации\n",
        "\n",
        "\n",
        "print(f\"Видео стабилизировано и сохранено в файл {result_file_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXKlT18K4x8U"
      },
      "source": [
        "> Однако в результате мы получаем проблему с переходом через черный экран\n",
        "> Чтобы решить эту проблему придется разбить видео на части, стабилизировать все фрагменты, кроме черного экрана.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "R2EMomU04x8U"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from vidstab import VidStab\n",
        "\n",
        "src_file_name = f\"{dataFolder}/result/final\"\n",
        "result_file_name = f\"{dataFolder}/result/final_stabilized_video.avi\"\n",
        "\n",
        "\n",
        "def is_black_frame(frame, threshold=10):\n",
        "    \"\"\"Проверяет, является ли кадр черным.\"\"\"\n",
        "    return cv2.mean(frame)[0] < threshold\n",
        "\n",
        "\n",
        "def find_video_segments(input_path):\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    frames = []\n",
        "    start_frame = None\n",
        "    is_current_frame_black = False\n",
        "    previous_frame_black = False\n",
        "\n",
        "    current_frame = 0\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:  # Видео закончилось\n",
        "            if start_frame is not None and current_frame - 1 != start_frame:\n",
        "                # Добавляем последний сегмент, если он не заканчивается черным экраном\n",
        "                frames.append((start_frame, current_frame - 1, previous_frame_black))\n",
        "            break\n",
        "\n",
        "        is_current_frame_black = is_black_frame(frame)\n",
        "\n",
        "        if start_frame is None:\n",
        "            # Начало нового сегмента\n",
        "            start_frame = current_frame\n",
        "            previous_frame_black = is_current_frame_black\n",
        "        elif is_current_frame_black != previous_frame_black:\n",
        "            # Конец текущего сегмента и начало нового\n",
        "            frames.append((start_frame, current_frame - 1, previous_frame_black))\n",
        "            start_frame = current_frame\n",
        "            previous_frame_black = is_current_frame_black\n",
        "\n",
        "        current_frame += 1\n",
        "\n",
        "    cap.release()\n",
        "    return frames, fps\n",
        "\n",
        "\n",
        "def save_video_segments(input_path, segments):\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
        "    temp_files = []\n",
        "    is_black_segments = []  # Список для отслеживания, является ли сегмент черным экраном\n",
        "\n",
        "    for i, (start_frame, end_frame, is_black) in enumerate(segments):\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
        "        segment_filename = f\"{dataFolder}/temp/pre_segment_{i}.avi\"\n",
        "        temp_files.append(segment_filename)\n",
        "        is_black_segments.append(is_black)  # Сохраняем информацию о типе сегмента\n",
        "\n",
        "        if is_black:\n",
        "            # Для черных экранов просто сохраняем один кадр, так как не требуется стабилизация\n",
        "            ret, frame = cap.read()\n",
        "            height, width, layers = frame.shape\n",
        "            out = cv2.VideoWriter(segment_filename, fourcc, fps, (width, height))\n",
        "            out.write(frame)  # Записываем один кадр для сохранения времени сегмента\n",
        "        else:\n",
        "            # Для обычных сегментов сохраняем весь диапазон кадров\n",
        "            out = None\n",
        "            for _ in range(end_frame - start_frame + 1):\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "                if out is None:\n",
        "                    height, width, layers = frame.shape\n",
        "                    out = cv2.VideoWriter(segment_filename, fourcc, fps, (width, height))\n",
        "                out.write(frame)\n",
        "\n",
        "        if out is not None:\n",
        "            out.release()\n",
        "\n",
        "    cap.release()\n",
        "    return temp_files, is_black_segments  # Возвращаем информацию о файле и о том, является ли сегмент черным экраном\n",
        "\n",
        "\n",
        "def stabilize_and_merge(segments, final_output, fps, input_path):\n",
        "    stabilizer = VidStab()\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
        "    out = None\n",
        "\n",
        "    for i, (start_frame, end_frame, is_black) in enumerate(segments):\n",
        "        if is_black:\n",
        "            # Для черных сегментов просто копируем их в итоговое видео\n",
        "            cap = cv2.VideoCapture(input_path)\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
        "            for _ in range(end_frame - start_frame + 1):\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "                if out is None:\n",
        "                    height, width, layers = frame.shape\n",
        "                    out = cv2.VideoWriter(final_output, fourcc, fps, (width, height))\n",
        "                out.write(frame)\n",
        "            cap.release()\n",
        "        else:\n",
        "            # Стабилизируем сегмент\n",
        "            segment_path = f\"{dataFolder}/temp/pre_segment_{i}.avi\"\n",
        "            stabilized_path = segment_path.replace(\"pre\", \"stabilized\")\n",
        "            stabilizer.stabilize(input_path=segment_path, output_path=stabilized_path)\n",
        "\n",
        "            # Добавляем стабилизированный сегмент в итоговое видео\n",
        "            cap = cv2.VideoCapture(stabilized_path)\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "                if out is None:\n",
        "                    height, width, layers = frame.shape\n",
        "                    out = cv2.VideoWriter(final_output, fourcc, fps, (width, height))\n",
        "                out.write(frame)\n",
        "            cap.release()\n",
        "\n",
        "    if out is not None:\n",
        "        out.release()\n",
        "\n",
        "\n",
        "# Использование\n",
        "video_segments, fps = find_video_segments(src_file_name)  # Пример сегментов, замените этими значениями реальные сегменты\n",
        "temp_files = save_video_segments(src_file_name, video_segments)\n",
        "stabilize_and_merge(video_segments, result_file_name, fps, src_file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTGSPD4N4x8Y"
      },
      "source": [
        "> Обратите внимание, final_cut_video - 204 мб, stabilized_file - 18 мб. Оба файла в форматах без потери качества: rawvideo и FFV1 соответственно.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Luh2SWn4x8Z"
      },
      "source": [
        "### Полезные преобразования\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SY3wzfCs4x8Z",
        "outputId": "d47f4dfa-7475-4cb0-bf7e-7d88a72d2683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video optical_flow_stabilized_compared.mp4.\n",
            "MoviePy - Writing audio in optical_flow_stabilized_comparedTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video optical_flow_stabilized_compared.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready optical_flow_stabilized_compared.mp4\n",
            "Moviepy - Building video final_stabilized_video_compared.mp4.\n",
            "MoviePy - Writing audio in final_stabilized_video_comparedTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video final_stabilized_video_compared.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t: 100%|█████████▉| 789/791 [00:18<00:00, 36.91it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/data/result/final_stabilized_video.avi, 230400 bytes wanted but 0 bytes read,at frame 790/791, at time 131.67/131.67 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready final_stabilized_video_compared.mp4\n"
          ]
        }
      ],
      "source": [
        "# Сопоставить видео\n",
        "from moviepy.editor import VideoFileClip, clips_array\n",
        "\n",
        "\n",
        "def comparevideo(path1, path2, path3):\n",
        "    # Загрузить оба видеофайла\n",
        "    video1 = VideoFileClip(path1)\n",
        "    video2 = VideoFileClip(path2)\n",
        "\n",
        "    # Убедиться, что оба видео имеют одинаковую высоту\n",
        "    video1_resized = video1.resize(height=video2.h)\n",
        "\n",
        "    # Создать массив из видео для горизонтального объединения\n",
        "    final_clip = clips_array([[video1_resized, video2]])\n",
        "\n",
        "    # Экспортировать итоговое видео\n",
        "    final_clip.write_videofile(path3, codec=\"libx264\")\n",
        "\n",
        "\n",
        "comparevideo(\"/content/data/result/final\", \"/content/data/result/optical_flow_stabilized.avi\", \"optical_flow_stabilized_compared.mp4\")\n",
        "comparevideo(\"/content/data/result/final\", \"/content/data/result/final_stabilized_video.avi\", \"final_stabilized_video_compared.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_7zgfCh4x8b",
        "outputId": "616384fb-f637-4de4-da44-69d6704f501d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Building video ./data/result/src.mp4.\n",
            "Moviepy - Writing video ./data/result/src.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready ./data/result/src.mp4\n"
          ]
        }
      ],
      "source": [
        "src_files_folder = f\"{dataFolder}/src\"\n",
        "comparevideo(f\"{src_files_folder}/01_fg_1.mp4\", f\"{src_files_folder}/01_bg_1.mp4\", f\"{dataFolder}/result/compare.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXRFq3MF4x8e"
      },
      "outputs": [],
      "source": [
        "# Факультативно. Стабилизируем видеопоток для публичного примера\n",
        "from vidstab import VidStab, download_ostrich_video\n",
        "\n",
        "path = f\"{dataFolder}/src/ostrich.mp4\"\n",
        "download_ostrich_video(path)\n",
        "stabilizer = VidStab()\n",
        "stabilizer.stabilize(path, f\"{dataFolder}/result/ostrich_stabilized.avi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POa1rHh_4x8f"
      },
      "outputs": [],
      "source": [
        "# Сохраним видео в animated gif\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "\n",
        "def videoToGif(fname, fps=15):\n",
        "    # Загрузить видеофайл\n",
        "    video = VideoFileClip(f\"{dataFolder}{fname}\")\n",
        "    # Сохранить вырезанный фрагмент в виде GIF с частотой кадров 15 fps\n",
        "    video.write_gif(f\"{dataFolder}{''.join(fname.split('.')[:-1])}.gif\", fps=fps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbLuYBDM4x8g",
        "outputId": "83d45e19-a045-4ecd-a0ed-39b355e2133f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Building file ./data/Mating3.gif with imageio.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        }
      ],
      "source": [
        "videoToGif(\"Mating3.mp4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nsryn3Ys4x8h"
      },
      "source": [
        "## Фильтрация шума\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "7I02WQds4x8i"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "src_file_name = f\"{dataFolder}/result/final_stabilized_video.avi\"\n",
        "result_file_name = f\"{dataFolder}/result/filtered_video.avi\"\n",
        "\n",
        "# Открытие исходного видео\n",
        "cap = cv2.VideoCapture(src_file_name)\n",
        "\n",
        "# Получение параметров исходного видео\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# Создание объекта записи видео\n",
        "out = cv2.VideoWriter(result_file_name, cv2.VideoWriter_fourcc(*\"DIVX\"), fps, (frame_width, frame_height))\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Применение фильтров к кадру\n",
        "    blur = cv2.blur(frame, (5, 5))\n",
        "    gaussian = cv2.GaussianBlur(frame, (5, 5), 0)\n",
        "    median = cv2.medianBlur(frame, 5)\n",
        "\n",
        "    # Объединение результатов фильтрации в одно изображение\n",
        "    top_half = np.hstack((blur, gaussian))\n",
        "    bottom_half = np.hstack((median, frame))\n",
        "    combined_frame = np.vstack((top_half, bottom_half))\n",
        "\n",
        "    # Уменьшаем размер комбинированного кадра до оригинального размера для сохранения\n",
        "    combined_frame_resized = cv2.resize(combined_frame, (frame_width, frame_height))\n",
        "\n",
        "    # Запись комбинированного кадра\n",
        "    out.write(combined_frame_resized)\n",
        "\n",
        "# Освобождение ресурсов\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXOBqIPO4x8j"
      },
      "source": [
        "### Методы заполнения на основе диффузии\n",
        "\n",
        "Методы заполнения на основе диффузии используются для восстановления утраченных или поврежденных частей изображений путем постепенного распространения информации о текстуре и интенсивности из неповрежденных областей в области, подлежащие восстановлению. Один из наиболее известных методов диффузии - это алгоритм заполнения по Навье-Стоксу, основанный на концепции, используемой в компьютерной графике для синтеза текстур.\n",
        "\n",
        "Прямая реализация таких алгоритмов может быть довольно сложной, особенно в контексте короткого примера кода, но я могу показать вам базовую иллюстрацию концепции диффузии на примере простой линейной диффузии для изображения. Это не будет полноценным методом заполнения на основе диффузии, но позволит вам понять основную идею.\n",
        "\n",
        "Для более продвинутых методов, таких как заполнение по Навье-Стоксу, я бы рекомендовал обратиться к специализированным библиотекам и исследованиям в области обработки изображений.\n",
        "\n",
        "В качестве примера рассмотрим простую диффузию, где каждый пиксель изображения обновляется на основе среднего значения его непосредственных соседей. Это может быть рассмотрено как базовая форма диффузии.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Smkc650h4x8k"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def diffuse_image(image, iterations=10):\n",
        "    img = image.astype(float)\n",
        "    for _ in range(iterations):\n",
        "        # Вычисляем среднее значение соседних пикселей\n",
        "        kernel = np.array([[0.05, 0.2, 0.05], [0.2, -1, 0.2], [0.05, 0.2, 0.05]])\n",
        "        diffused_img = cv2.filter2D(img, -1, kernel) + img\n",
        "        img = np.clip(diffused_img, 0, 255)\n",
        "    return img.astype(np.uint8)\n",
        "\n",
        "\n",
        "# Загрузка изображения\n",
        "image_path = f\"{dataFolder}/src/def1.jpg\"\n",
        "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Применение простой диффузии\n",
        "diffused_image = diffuse_image(image)\n",
        "\n",
        "# Показать изображение\n",
        "cv2.imwrite(f\"{dataFolder}/result/def2.png\", diffused_image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8fPMfuB4x8l"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Загрузка изображения\n",
        "image = cv2.imread(f\"{dataFolder}/src/def1.jpg\")\n",
        "\n",
        "# Создание маски для повреждённой области (предположим, что это белые пиксели)\n",
        "mask = np.zeros(image.shape[:2], np.uint8)  # Создаём черную маску\n",
        "# Допустим, у нас есть область с координатами [x, y, width, height], которую нужно восстановить\n",
        "# Например:\n",
        "x, y, width, height = 50, 50, 100, 100  # Координаты повреждённой области\n",
        "mask[y : y + height, x : x + width] = 255  # Отмечаем повреждённую область на маске белым цветом\n",
        "\n",
        "# Применение функции inpaint для заполнения повреждённых участков\n",
        "inpaint_radius = 3  # Радиус каждого восстанавливаемого патча\n",
        "inpaint_method = cv2.INPAINT_TELEA  # Можно использовать cv2.INPAINT_TELEA или cv2.INPAINT_NS\n",
        "restored_image = cv2.inpaint(image, mask, inpaint_radius, inpaint_method)\n",
        "\n",
        "# Показываем результаты\n",
        "# cv2.imshow('Original Image', image)\n",
        "# cv2.imshow('Mask', mask)\n",
        "# cv2.imshow('Restored Image', restored_image)\n",
        "cv2.imwrite(f\"{dataFolder}/result/def3_mask.png\", mask)\n",
        "cv2.imwrite(f\"{dataFolder}/result/def3_rest.png\", restored_image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8FVnp1A4x8n"
      },
      "source": [
        "## Карты прозрачности\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIW6-XSF4x8n"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "src_file_name1 = f\"{dataFolder}/src/01_fg_1.mp4\"\n",
        "src_file_name2 = f\"{dataFolder}/src/01_bg_1.mp4\"\n",
        "result_file_name = f\"{dataFolder}/result/overlay_video.mp4\"\n",
        "\n",
        "# Параметры зеленого цвета для хромакея\n",
        "green_lower = np.array([36, 25, 25])\n",
        "green_upper = np.array([86, 255, 255])\n",
        "\n",
        "# Открытие видеофайлов\n",
        "cap_foreground = cv2.VideoCapture(src_file_name1)\n",
        "cap_background = cv2.VideoCapture(src_file_name2)\n",
        "\n",
        "# Получение параметров видео\n",
        "frame_width = int(cap_background.get(3))\n",
        "frame_height = int(cap_background.get(4))\n",
        "fps = cap_background.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# Создание объекта для записи видео\n",
        "out = cv2.VideoWriter(result_file_name, cv2.VideoWriter_fourcc(*\"MP4V\"), fps, (frame_width, frame_height))\n",
        "\n",
        "while cap_foreground.isOpened() and cap_background.isOpened():\n",
        "    ret_foreground, frame_foreground = cap_foreground.read()\n",
        "    ret_background, frame_background = cap_background.read()\n",
        "\n",
        "    if not ret_foreground or not ret_background:\n",
        "        break\n",
        "\n",
        "    # Изменение размера переднего плана, если необходимо, для соответствия размеру фона\n",
        "    if frame_foreground.shape[:2] != frame_background.shape[:2]:\n",
        "        frame_foreground = cv2.resize(frame_foreground, (frame_background.shape[1], frame_background.shape[0]))\n",
        "\n",
        "    # Конвертация изображения в HSV и создание маски для зеленого фона\n",
        "    hsv = cv2.cvtColor(frame_foreground, cv2.COLOR_BGR2HSV)\n",
        "    mask = cv2.inRange(hsv, green_lower, green_upper)\n",
        "    mask_inv = cv2.bitwise_not(mask)\n",
        "\n",
        "    # Применение маски к переднему плану и фону\n",
        "    foreground = cv2.bitwise_and(frame_foreground, frame_foreground, mask=mask_inv)\n",
        "    background = cv2.bitwise_and(frame_background, frame_background, mask=mask)\n",
        "\n",
        "    # Наложение изображений\n",
        "    result = cv2.add(foreground, background)\n",
        "\n",
        "    # Запись в файл\n",
        "    out.write(result)\n",
        "\n",
        "    cv2.imshow(\"Result\", result)\n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "        break\n",
        "\n",
        "cap_foreground.release()\n",
        "cap_background.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}